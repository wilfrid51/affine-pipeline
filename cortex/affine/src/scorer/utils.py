"""
Scorer Utility Functions

Helper functions for the scoring algorithm.
"""

from typing import List, Dict, Set, Tuple
from itertools import combinations
import math


def generate_all_subsets(envs: List[str], max_layers: int = None) -> Dict[str, Dict[str, any]]:
    """Generate all possible subsets (environment combinations) with layer information.
    
    Args:
        envs: List of environment names
        max_layers: Maximum number of layers to evaluate. If total envs > max_layers,
                   only the top max_layers will be evaluated (e.g., if 8 envs and max_layers=6,
                   evaluate L3-L8, skipping L1-L2)
        
    Returns:
        Dict mapping subset_key to subset metadata:
        {
            "L1_sat": {
                "layer": 1,
                "envs": ["sat"],
                "key": "L1_sat"
            },
            "L2_sat_abd": {
                "layer": 2,
                "envs": ["sat", "abd"],
                "key": "L2_sat_abd"
            },
            ...
        }
    """
    subsets = {}
    n = len(envs)
    
    # Calculate starting layer (skip lower layers if total > max_layers)
    if max_layers is not None and n > max_layers:
        start_layer = n - max_layers + 1  # e.g., 8 envs, max 6 layers: start from L3
    else:
        start_layer = 1
    
    # Generate all combinations for each layer
    for layer in range(start_layer, n + 1):
        for env_combo in combinations(envs, layer):
            # Sort environments alphabetically for consistent keys
            sorted_envs = sorted(env_combo)
            
            # Create subset key: L{layer}_{env1}_{env2}_{...}
            subset_key = f"L{layer}_{'_'.join(sorted_envs)}"
            
            subsets[subset_key] = {
                "layer": layer,
                "envs": sorted_envs,
                "key": subset_key
            }
    
    return subsets


def calculate_layer_weights(n_envs: int, base: int = 2, start_layer: int = 1) -> Dict[int, float]:
    """Calculate weight for each layer based on exponential growth.
    
    Layer weight = N × base^(layer_index)
    where layer_index = layer - start_layer (starts from 0)
    
    Args:
        n_envs: Number of environments
        base: Exponent base (default: 2)
        start_layer: Starting layer number (default: 1)
        
    Returns:
        Dict mapping layer number to total layer weight:
        If start_layer=1: {1: N, 2: N*2, 3: N*4, 4: N*8, ...}
        If start_layer=3: {3: N, 4: N*2, 5: N*4, 6: N*8, ...}
    """
    layer_weights = {}
    for layer in range(start_layer, n_envs + 1):
        layer_index = layer - start_layer  # Relative index from start
        layer_weights[layer] = n_envs * (base ** layer_index)
    return layer_weights


def calculate_subset_weights(
    subsets: Dict[str, Dict[str, any]],
    layer_weights: Dict[int, float]
) -> Dict[str, float]:
    """Calculate individual subset weights by distributing layer weights equally.
    
    Each subset in a layer gets: layer_weight / num_subsets_in_layer
    
    Args:
        subsets: Dict of subset metadata
        layer_weights: Dict mapping layer to total weight
        
    Returns:
        Dict mapping subset_key to individual weight
    """
    # Count subsets per layer
    layer_counts = {}
    for subset_info in subsets.values():
        layer = subset_info["layer"]
        layer_counts[layer] = layer_counts.get(layer, 0) + 1
    
    # Distribute layer weights equally among subsets
    subset_weights = {}
    for subset_key, subset_info in subsets.items():
        layer = subset_info["layer"]
        layer_weight = layer_weights[layer]
        num_subsets = layer_counts[layer]
        
        subset_weights[subset_key] = layer_weight / num_subsets
    
    return subset_weights


def geometric_mean(values: List[float]) -> float:
    """Calculate geometric mean of a list of values.
    
    Formula: (∏ values)^(1/N)
    
    Args:
        values: List of numeric values
        
    Returns:
        Geometric mean, or 0.0 if any value is 0
    """
    if not values:
        return 0.0
    
    # If any value is 0, return 0 (penalizes poor performance)
    if any(v <= 0 for v in values):
        return 0.0
    
    # Calculate product and take Nth root
    n = len(values)
    product = 1.0
    for v in values:
        product *= v
    
    return product ** (1.0 / n)


def calculate_required_score(
    prior_score: float,
    error_rate_reduction: float = 0.2,
    min_improvement: float = 0.02,
    max_improvement: float = 0.1
) -> float:
    """Calculate required score to beat prior.
    
    The threshold is calculated as: prior_score + improvement_delta
    where improvement_delta is determined by:
    1. Error rate reduction: (1 - prior_score) × error_rate_reduction
    2. Minimum improvement: min_improvement
    3. Maximum improvement cap: max_improvement
    
    Final formula: prior_score + min(max(err_delta, min_improvement), max_improvement)
    
    Args:
        prior_score: Score of the earlier miner (0.0 to 1.0)
        error_rate_reduction: Required error rate reduction ratio (default: 0.2 for 20%)
        min_improvement: Minimum absolute improvement required (default: 0.02)
        max_improvement: Maximum improvement cap (default: 0.1 for 10%)
        
    Returns:
        Required score to dominate the prior miner
        
    Examples:
        prior=0.09, err_red=0.2, min_imp=0.02, max_imp=0.1
        -> err_delta = (1-0.09)*0.2 = 0.182
        -> improvement = min(max(0.182, 0.02), 0.1) = 0.1
        -> threshold = 0.09 + 0.1 = 0.19 (19%)
    """
    # Calculate error rate reduction delta
    error_delta = (1.0 - prior_score) * error_rate_reduction
    
    # Choose improvement: max of error_delta and min_improvement, capped by max_improvement
    improvement = min(max(error_delta, min_improvement), max_improvement)
    
    # Final threshold, capped at 1.0
    return min(prior_score + improvement, 1.0)


def normalize_weights(weights: Dict[int, float]) -> Dict[int, float]:
    """Normalize weights to sum to 1.0.
    
    Args:
        weights: Dict mapping UID to raw weight
        
    Returns:
        Dict mapping UID to normalized weight (0.0 to 1.0)
    """
    total = sum(weights.values())
    
    if total == 0:
        return {uid: 0.0 for uid in weights}
    
    return {uid: w / total for uid, w in weights.items()}


def apply_min_threshold(
    weights: Dict[int, float],
    threshold: float = 0.01,
    redistribute_to_uid_zero: bool = False
) -> Dict[int, float]:
    """Set weights below threshold to 0, optionally redistribute to uid 0.

    Args:
        weights: Dict mapping UID to weight
        threshold: Minimum weight threshold (default: 0.01 for 1%)
        redistribute_to_uid_zero: If True, add sub-threshold weights to uid 0

    Returns:
        Dict with sub-threshold weights set to 0 (and redistributed to uid 0 if enabled)
    """
    if not redistribute_to_uid_zero:
        return {
            uid: (w if w >= threshold else 0.0)
            for uid, w in weights.items()
        }

    # Calculate total weight below threshold (excluding uid 0)
    below_threshold_weight = sum(
        w for uid, w in weights.items()
        if uid != 0 and w > 0 and w < threshold
    )

    # Apply threshold and set below-threshold weights to 0
    result = {
        uid: (w if w >= threshold else 0.0)
        for uid, w in weights.items()
    }

    # Add redistributed weight to uid 0
    if below_threshold_weight > 0:
        result[0] = result.get(0, 0.0) + below_threshold_weight

    return result


def aggregate_by_layer(
    subset_weights: Dict[str, float]
) -> Dict[int, float]:
    """Aggregate subset weights by layer.
    
    Args:
        subset_weights: Dict mapping subset_key to weight contribution
        
    Returns:
        Dict mapping layer number to total weight
    """
    layer_totals = {}
    
    for subset_key, weight in subset_weights.items():
        # Extract layer from key (format: L{layer}_...)
        layer_str = subset_key.split('_')[0]  # "L3"
        layer = int(layer_str[1:])  # 3
        
        layer_totals[layer] = layer_totals.get(layer, 0.0) + weight
    
    return layer_totals


def format_score_table_row(
    uid: int,
    hotkey: str,
    env_scores: Dict[str, float],
    env_thresholds: Dict[str, float],
    env_samples: Dict[str, int],
    layer_weights: Dict[int, float],
    total_weight: float,
    is_valid: bool
) -> str:
    """Format a row for the score summary table.
    
    Args:
        uid: Miner UID
        hotkey: Miner hotkey (will be truncated)
        env_scores: Environment scores
        env_thresholds: Threshold upper bounds per environment
        env_samples: Sample counts per environment
        layer_weights: Weights by layer
        total_weight: Total cumulative weight
        is_valid: Whether miner is valid for scoring
        
    Returns:
        Formatted table row string
    """
    # Truncate hotkey
    hotkey_short = f"{hotkey[:8]}..."
    
    # Format environment columns
    env_cols = []
    for env in sorted(env_scores.keys()):
        score = env_scores.get(env, 0.0)
        threshold = env_thresholds.get(env, 0.0)
        samples = env_samples.get(env, 0)
        env_cols.append(f"{score:.3f}/{threshold:.3f}/{samples}")
    
    # Format layer weights
    layer_cols = [f"{layer_weights.get(i, 0.0):.4f}" for i in sorted(layer_weights.keys())]
    
    # Valid indicator
    valid_str = "✓" if is_valid else "✗"
    
    # Build row
    parts = [
        f"{uid:3d}",
        f"{hotkey_short:12s}",
        *env_cols,
        *layer_cols,
        f"{total_weight:.6f}",
        valid_str
    ]
    
    return " | ".join(parts)